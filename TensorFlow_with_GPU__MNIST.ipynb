{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow with GPU",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/mohSeSC/AdminLTE/blob/master/TensorFlow_with_GPU__MNIST.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "BlmQIFSLZDdc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Confirm TensorFlow can see the GPU\n",
        "\n",
        "Simply select \"GPU\" in the Accelerator drop-down in Notebook Settings (either through the Edit menu or the command palette at cmd/ctrl-shift-P)."
      ]
    },
    {
      "metadata": {
        "id": "QXRh0DPiZRyG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "metadata": {
        "id": "3IEVK-KFxi5Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "4937d0e3-ed7f-4002-871d-e351fffa38fc"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d1680108c58e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "t9ALbbpmY9rm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c5ee74e3-f88b-4660-dcba-354d09fa5659"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "  random_image_cpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
        "  net_cpu = tf.reduce_sum(net_cpu)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "# Test execution once to detect errors early.\n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise\n",
        "\n",
        "def cpu():\n",
        "  sess.run(net_cpu)\n",
        "  \n",
        "def gpu():\n",
        "  sess.run(net_gpu)\n",
        "  \n",
        "# Runs the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "8.350230318000058\n",
            "GPU (s):\n",
            "0.1842791589999706\n",
            "GPU speedup over CPU: 45x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uaYhirD_0HvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cca88abc-5a0c-4d36-8e47-45a632cc6f4a"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "006rhkst0iOI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist  # mnist is a dataset of 28x28 images of handwritten digits and their labels\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()  # unpacks images to x_train/x_test and labels to y_train/y_test\n",
        "\n",
        "x_train = tf.keras.utils.normalize(x_train, axis=1)  # scales data between 0 and 1\n",
        "x_test = tf.keras.utils.normalize(x_test, axis=1)  # scales data between 0 and 1\n",
        "\n",
        "model = tf.keras.models.Sequential()  # a basic feed-forward model\n",
        "model.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
        "\n",
        "model.compile(optimizer='adam',  # Good default optimizer to start with\n",
        "              loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
        "              metrics=['accuracy'])  # what to track\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X1VGdKrk1Wog",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "88efbd02-29da-4d45-a69d-c0cc6f7b8bbb"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=3)  # train the model\n",
        "\n",
        "val_loss, val_acc = model.evaluate(x_test, y_test)  # evaluate the out of sample data with model\n",
        "print(val_loss)  # model's loss (error)\n",
        "print(val_acc)  # model's accuracy"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.2679 - acc: 0.9208\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.1089 - acc: 0.9659\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0742 - acc: 0.9770\n",
            "10000/10000 [==============================] - 0s 30us/step\n",
            "0.08809038865827024\n",
            "0.9719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YbcG94o51fyu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('epic_num_reader.model')\n",
        "\n",
        "new_model = tf.keras.models.load_model('epic_num_reader.model')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xPGY4PkV2LGR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = new_model.predict(x_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cWbzMiTi2gLG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oLaWPPDU2Otz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "b49d00fc-20a9-4999-9d86-f18f86ad7e1f"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(np.argmax(predictions[0]))\n",
        "plt.imshow(x_test[0],cmap=plt.cm.binary)\n",
        "plt.show()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa985390dd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}